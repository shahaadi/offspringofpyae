{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ImageModel\n",
    "from model import compute_loss_and_accuracy\n",
    "import embeddings as em\n",
    "import numpy as np\n",
    "from mynn.optimizers.sgd import SGD\n",
    "from cogworks_data.language import get_data_path\n",
    "from pathlib import Path\n",
    "import json\n",
    "from batches import create_batches\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# run this model to train our single-layer neural network\n",
    "filename = get_data_path(\"captions_train2014.json\")\n",
    "with Path(filename).open() as f:\n",
    "    cocodata = json.load(f)\n",
    "\n",
    "# load saved image descriptor vectors\n",
    "import pickle\n",
    "with Path(get_data_path('resnet18_features.pkl')).open('rb') as f:\n",
    "    resnet18_features = pickle.load(f)\n",
    "\n",
    "\n",
    "resnet18_ids = set(resnet18_features.keys())\n",
    "cocodata['images'] = [\n",
    "  img for img in cocodata[\"images\"] if img[\"id\"] in resnet18_ids\n",
    "]\n",
    "cocodata['annotations'] = [\n",
    "  anot for anot in cocodata[\"annotations\"] if anot['image_id'] in resnet18_ids\n",
    "]\n",
    "\n",
    "#load glove\n",
    "glove = em.Glove()\n",
    "idf = em.IDF()\n",
    "\n",
    "image_ids, caption_ids, confusor_ids = create_batches(cocodata)\n",
    "image_ids, captions_ids, confusor_ids = shuffle(\n",
    "  image_ids, caption_ids, confusor_ids, random_state=0\n",
    ")\n",
    "\n",
    "data_len = image_ids.shape[0]\n",
    "test_idx = data_len // 5\n",
    "\n",
    "test_image_ids = image_ids[:test_idx]\n",
    "test_captions_ids = captions_ids[:test_idx]\n",
    "test_confusor_ids = confusor_ids[:test_idx]\n",
    "train_image_ids = image_ids[test_idx:]\n",
    "train_captions_ids = captions_ids[test_idx:]\n",
    "train_confusor_ids = confusor_ids[test_idx:]\n",
    "\n",
    "train_len = train_image_ids.shape[0]\n",
    "test_len = test_image_ids.shape[0]\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = ImageModel(512, 200)\n",
    "optim = SGD(model.parameters, learning_rate = 1e-3, momentum=0.9)\n",
    "\n",
    "for epoch_cnt in range(EPOCHS):\n",
    "    idxs = np.arange(train_len)\n",
    "    np.random.shuffle(idxs)\n",
    "    \n",
    "    for batch_cnt in range(0, train_len//BATCH_SIZE):\n",
    "        batch_indices = idxs[batch_cnt*BATCH_SIZE : (batch_cnt + 1)*BATCH_SIZE]\n",
    "        \n",
    "        batch_img_ids = train_image_ids[batch_indices]\n",
    "        batch_conf_ids = train_confusor_ids[batch_indices]\n",
    "        batch_caption_ids = train_captions_ids[batch_indices]\n",
    "\n",
    "        batch_imgs = np.empty((batch_img_ids.shape[0], 512))\n",
    "        batch_confs = np.empty((batch_conf_ids.shape[0], 512))\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "          batch_imgs[i] = resnet18_features[batch_img_ids[i]][0, :]\n",
    "          batch_confs[i] = resnet18_features[batch_conf_ids[i]][0, :]\n",
    "\n",
    "        batch_caps = np.empty((BATCH_SIZE, 200))\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "          batch_caps[i] = em.embed(\n",
    "            cocodata['annotations'][batch_caption_ids[i]]['caption'], idf, glove\n",
    "          )\n",
    "      \n",
    "        embedding_true, embedding_conf = model(batch_imgs, batch_confs)\n",
    "\n",
    "        # compute loss and accuracy using margin loss ranking\n",
    "        loss, accuracy = compute_loss_and_accuracy(batch_caps, embedding_true, embedding_conf) \n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        # optim.zero_grad()\n",
    "\n",
    "        print('epoch:', epoch_cnt, '\\tbatch:', batch_cnt, '\\tloss:', loss, '\\tacc:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
